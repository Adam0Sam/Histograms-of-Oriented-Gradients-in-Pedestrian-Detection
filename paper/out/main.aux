\relax 
\providecommand{\transparent@use}[1]{}
\abx@aux@refcontext{nty/global//global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\abx@aux@cite{0}{slootmans_2021_european}
\abx@aux@segm{0}{0}{slootmans_2021_european}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\abx@aux@cite{0}{faraji_2006_ccd}
\abx@aux@segm{0}{0}{faraji_2006_ccd}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\abx@aux@cite{0}{niebles2012edge}
\abx@aux@segm{0}{0}{niebles2012edge}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{zia_2015_why}
\abx@aux@segm{0}{0}{zia_2015_why}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background Information}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Histograms of Oriented Gradients}{2}{subsection.2.1}\protected@file@percent }
\newlabel{sec:hog}{{2.1}{2}{Histograms of Oriented Gradients}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}One Fundamental Property of Images}{2}{subsubsection.2.1.1}\protected@file@percent }
\abx@aux@cite{0}{niebles2012edge}
\abx@aux@segm{0}{0}{niebles2012edge}
\abx@aux@cite{0}{niebles2012edge}
\abx@aux@segm{0}{0}{niebles2012edge}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{niebles2012edge}
\abx@aux@segm{0}{0}{niebles2012edge}
\abx@aux@cite{0}{niebles2012edge}
\abx@aux@segm{0}{0}{niebles2012edge}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Representation of the three types of edge that can be found in image analysis. Source: \blx@tocontentsinit {0}\cite {niebles2012edge}}}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pixel_intensity}{{1}{3}{Representation of the three types of edge that can be found in image analysis.\\Source: \cite {niebles2012edge}}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Gradient Computation}{3}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{sec:deriv_mask}{{2.1.2}{3}{Gradient Computation}{subsubsection.2.1.2}{}}
\newlabel{eq:convolution}{{2.1}{3}{Gradient Computation}{equation.2.1}{}}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\abx@aux@cite{0}{niebles2012edge}
\abx@aux@segm{0}{0}{niebles2012edge}
\newlabel{central_1}{{2.2}{4}{Gradient Computation}{equation.2.2}{}}
\newlabel{central_2}{{2.3}{4}{Gradient Computation}{equation.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Three types of finite differences and their corresponding derivative masks. Source: Image by me}}{4}{figure.caption.2}\protected@file@percent }
\newlabel{fig:finite_differences}{{2}{4}{Three types of finite differences and their corresponding derivative masks. Source: Image by me}{figure.caption.2}{}}
\newlabel{finite_top}{{2.4}{4}{Gradient Computation}{equation.2.4}{}}
\newlabel{finite_left}{{2.5}{4}{Gradient Computation}{equation.2.5}{}}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\abx@aux@cite{0}{lowe_2004_distinctive}
\abx@aux@segm{0}{0}{lowe_2004_distinctive}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\newlabel{finite_bottom}{{2.6}{5}{Gradient Computation}{equation.2.6}{}}
\newlabel{finite_right}{{2.7}{5}{Gradient Computation}{equation.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a) Calculation of gradient vector. Source: Image by me (b) Visualisation of gradient vectors. Source: \blx@tocontentsinit {0}\cite {shidlovskiy_2020_reducing}}}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:pythagorean}{{3}{5}{(a) Calculation of gradient vector. Source: Image by me (b) Visualisation of gradient vectors. Source: \cite {shidlovskiy_2020_reducing}}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Orientation Binning}{5}{subsubsection.2.1.3}\protected@file@percent }
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A 128x64 image divided into a grid of 8x8 pixel sized cells. Source: \blx@tocontentsinit {0}\cite {shidlovskiy_2020_reducing}}}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig:cells}{{4}{6}{A 128x64 image divided into a grid of 8x8 pixel sized cells. Source: \cite {shidlovskiy_2020_reducing}}{figure.caption.4}{}}
\newlabel{eq:bin}{{2.8}{6}{Orientation Binning}{equation.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A histogram with 9 equally distributed bins. Source: Image by me}}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:histogram_bins}{{5}{6}{A histogram with 9 equally distributed bins. Source: Image by me}{figure.caption.5}{}}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Block Normalisation}{7}{subsubsection.2.1.4}\protected@file@percent }
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Construction of histogram blocks of size (2,2). Source: \blx@tocontentsinit {0}\cite {shidlovskiy_2020_reducing}}}{8}{figure.caption.6}\protected@file@percent }
\newlabel{fig:normalisation}{{6}{8}{Construction of histogram blocks of size (2,2). Source: \cite {shidlovskiy_2020_reducing}}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Feature Vector Dimensionality}{8}{subsubsection.2.1.5}\protected@file@percent }
\newlabel{sec:feature_vector_dimensionality}{{2.1.5}{8}{Feature Vector Dimensionality}{subsubsection.2.1.5}{}}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\abx@aux@cite{0}{shidlovskiy_2020_reducing}
\abx@aux@segm{0}{0}{shidlovskiy_2020_reducing}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces An overview of the HOG feature extraction chain. Source: Adapted by me from \blx@tocontentsinit {0}\cite {dalal_2005_histograms}}}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:hog_pipeline}{{7}{9}{An overview of the HOG feature extraction chain. Source: Adapted by me from \cite {dalal_2005_histograms}}{figure.caption.7}{}}
\abx@aux@cite{0}{what_is_ml}
\abx@aux@segm{0}{0}{what_is_ml}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A 128x64 sized image with cells that contain 8x8 pixels and blocks that contain 4x4 cells. The top left-most and bottom-right most block coordinates are each expressed using the aforementioned bounds. Source: Adapted by me from \blx@tocontentsinit {0}\cite {shidlovskiy_2020_reducing}}}{10}{figure.caption.8}\protected@file@percent }
\newlabel{fig:center_coords}{{8}{10}{A 128x64 sized image with cells that contain 8x8 pixels and blocks that contain 4x4 cells. The top left-most and bottom-right most block coordinates are each expressed using the aforementioned bounds. Source: Adapted by me from \cite {shidlovskiy_2020_reducing}}{figure.caption.8}{}}
\newlabel{vector_dimensions}{{2.9}{10}{Feature Vector Dimensionality}{equation.2.9}{}}
\abx@aux@cite{0}{supervised_learning}
\abx@aux@segm{0}{0}{supervised_learning}
\abx@aux@cite{0}{supervised_learning}
\abx@aux@segm{0}{0}{supervised_learning}
\abx@aux@cite{0}{derek_2020_svm}
\abx@aux@segm{0}{0}{derek_2020_svm}
\abx@aux@cite{0}{supervised_learning}
\abx@aux@segm{0}{0}{supervised_learning}
\abx@aux@cite{0}{supervised_learning}
\abx@aux@segm{0}{0}{supervised_learning}
\abx@aux@cite{0}{cornell_svm}
\abx@aux@segm{0}{0}{cornell_svm}
\abx@aux@cite{0}{chang_lin_2011_libsvm}
\abx@aux@segm{0}{0}{chang_lin_2011_libsvm}
\abx@aux@cite{0}{derek_2020_svm}
\abx@aux@segm{0}{0}{derek_2020_svm}
\abx@aux@cite{0}{cornell_decision_trees}
\abx@aux@segm{0}{0}{cornell_decision_trees}
\abx@aux@cite{0}{cornell_naive_bayes}
\abx@aux@segm{0}{0}{cornell_naive_bayes}
\abx@aux@cite{0}{cornell_nn}
\abx@aux@segm{0}{0}{cornell_nn}
\abx@aux@cite{0}{ng_support}
\abx@aux@segm{0}{0}{ng_support}
\abx@aux@cite{0}{derek_2020_svm}
\abx@aux@segm{0}{0}{derek_2020_svm}
\abx@aux@cite{0}{derek_2020_svm}
\abx@aux@segm{0}{0}{derek_2020_svm}
\abx@aux@cite{0}{svm_mri}
\abx@aux@segm{0}{0}{svm_mri}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Supervised Machine Learning}{11}{subsection.2.2}\protected@file@percent }
\newlabel{sec:supervised_ml}{{2.2}{11}{Supervised Machine Learning}{subsection.2.2}{}}
\abx@aux@cite{0}{cornell_svm_notes}
\abx@aux@segm{0}{0}{cornell_svm_notes}
\abx@aux@cite{0}{derek_2020_svm}
\abx@aux@segm{0}{0}{derek_2020_svm}
\abx@aux@cite{0}{cornell_perceptron}
\abx@aux@segm{0}{0}{cornell_perceptron}
\abx@aux@cite{0}{ng_support}
\abx@aux@segm{0}{0}{ng_support}
\abx@aux@cite{0}{cornell_svm_notes}
\abx@aux@segm{0}{0}{cornell_svm_notes}
\abx@aux@cite{0}{cornell_svm_notes}
\abx@aux@segm{0}{0}{cornell_svm_notes}
\abx@aux@cite{0}{cornell_svm}
\abx@aux@segm{0}{0}{cornell_svm}
\abx@aux@cite{0}{cornell_svm_notes}
\abx@aux@segm{0}{0}{cornell_svm_notes}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Support Vector Machines}{12}{subsection.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A 2 dimensional space, where each data point has 2 features (one abscissa and one ordinate component) (Left:) Two different separating hyperplanes for the same data set (the multiple possibles hyperplanes of, for example, the perceptron algorithm). (Right:) The maximum margin hyperplane (the only possible hyperplane of the SVM algorithm). Source: \blx@tocontentsinit {0}\cite {cornell_svm_notes}}}{12}{figure.caption.9}\protected@file@percent }
\newlabel{fig:hyperplane}{{9}{12}{A 2 dimensional space, where each data point has 2 features (one abscissa and one ordinate component) (Left:) Two different separating hyperplanes for the same data set (the multiple possibles hyperplanes of, for example, the perceptron algorithm). (Right:) The maximum margin hyperplane (the only possible hyperplane of the SVM algorithm). Source: \cite {cornell_svm_notes}}{figure.caption.9}{}}
\abx@aux@cite{0}{cornell_svm_notes}
\abx@aux@segm{0}{0}{cornell_svm_notes}
\abx@aux@cite{0}{cornell_svm_notes}
\abx@aux@segm{0}{0}{cornell_svm_notes}
\abx@aux@cite{0}{ng_support}
\abx@aux@segm{0}{0}{ng_support}
\newlabel{margin_expr}{{2.10}{13}{Support Vector Machines}{equation.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The projection of a data point onto the hyperplane. Source: \blx@tocontentsinit {0}\cite {cornell_svm_notes}}}{13}{figure.caption.10}\protected@file@percent }
\newlabel{fig:hyperplane_geometry}{{10}{13}{The projection of a data point onto the hyperplane. Source: \cite {cornell_svm_notes}}{figure.caption.10}{}}
\abx@aux@cite{0}{quadratic_programming}
\abx@aux@segm{0}{0}{quadratic_programming}
\abx@aux@cite{0}{cornell_svm_notes}
\abx@aux@segm{0}{0}{cornell_svm_notes}
\abx@aux@cite{0}{chang_lin_2011_libsvm}
\abx@aux@segm{0}{0}{chang_lin_2011_libsvm}
\abx@aux@cite{0}{inria_improved}
\abx@aux@segm{0}{0}{inria_improved}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{cornell_svm_continued}
\abx@aux@segm{0}{0}{cornell_svm_continued}
\newlabel{hyper_inequality}{{2.11}{14}{Support Vector Machines}{equation.2.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Soft SVM Constraints}{14}{subsubsection.2.3.1}\protected@file@percent }
\newlabel{sec:soft_constraint_svm}{{2.3.1}{14}{Soft SVM Constraints}{subsubsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A Data set with two classes and an outlier. Source: Image by me}}{14}{figure.caption.11}\protected@file@percent }
\newlabel{fig:outliers}{{11}{14}{A Data set with two classes and an outlier. Source: Image by me}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces (Image 1: ) An Image containing three people/pedestrians in a building. Source: \href  {https://www.istockphoto.com/photo/business-people-taking-a-break-gm639259132-115111535}{istockphoto.com} (Image 2:) An Image containing three mannequins in a store window. Source: \href  {https://theshopcompany.com/blog/Mannequins_and_Dressforms_Who_Uses_What}{theshopcompany.com} (Image 1 and 2 Hog Features): Computed HOG Features of Image 1 and Image 2. Source: Image by me}}{15}{figure.caption.12}\protected@file@percent }
\newlabel{fig:manequin_features}{{12}{15}{(Image 1: ) An Image containing three people/pedestrians in a building. Source: \href {https://www.istockphoto.com/photo/business-people-taking-a-break-gm639259132-115111535}{istockphoto.com} (Image 2:) An Image containing three mannequins in a store window. Source: \href {https://theshopcompany.com/blog/Mannequins_and_Dressforms_Who_Uses_What}{theshopcompany.com} (Image 1 and 2 Hog Features): Computed HOG Features of Image 1 and Image 2. Source: Image by me}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{15}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dependant Variables}{15}{subsection.3.1}\protected@file@percent }
\newlabel{sec:dependent_variables}{{3.1}{15}{Dependant Variables}{subsection.3.1}{}}
\abx@aux@cite{0}{piotrdollr_2012_crosstalk}
\abx@aux@segm{0}{0}{piotrdollr_2012_crosstalk}
\abx@aux@cite{0}{zhou_2021_research}
\abx@aux@segm{0}{0}{zhou_2021_research}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{inria_improved}
\abx@aux@segm{0}{0}{inria_improved}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Dependent variables for the experiment}}{16}{table.caption.13}\protected@file@percent }
\newlabel{table:dependent_variables}{{1}{16}{Dependent variables for the experiment}{table.caption.13}{}}
\newlabel{eq:number_sets}{{3.1}{16}{Dependant Variables}{equation.3.1}{}}
\abx@aux@cite{0}{dollar_2009_pedestrian}
\abx@aux@segm{0}{0}{dollar_2009_pedestrian}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dollar_2009_pedestrian}
\abx@aux@segm{0}{0}{dollar_2009_pedestrian}
\abx@aux@cite{0}{karthika_2020_addressing}
\abx@aux@segm{0}{0}{karthika_2020_addressing}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Data Sets}{17}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Labeled Pedestrian Data Set Sources}{17}{subsubsection.3.2.1}\protected@file@percent }
\abx@aux@cite{0}{everingham_2009_pascal}
\abx@aux@segm{0}{0}{everingham_2009_pascal}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\abx@aux@cite{0}{mathworks_vbbLabeler}
\abx@aux@segm{0}{0}{mathworks_vbbLabeler}
\abx@aux@cite{0}{dollar_2009_pedestrian}
\abx@aux@segm{0}{0}{dollar_2009_pedestrian}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{karthika_2020_addressing}
\abx@aux@segm{0}{0}{karthika_2020_addressing}
\abx@aux@cite{0}{dollar_2009_pedestrian}
\abx@aux@segm{0}{0}{dollar_2009_pedestrian}
\abx@aux@cite{0}{dollar_2009_pedestrian}
\abx@aux@segm{0}{0}{dollar_2009_pedestrian}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Caltech Data Set Transformation}{18}{subsubsection.3.2.2}\protected@file@percent }
\newlabel{sec:caltech_trasnform}{{3.2.2}{18}{Caltech Data Set Transformation}{subsubsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Window Size Samples}{19}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces A high level overview flowchart of the process of initializing and saving the total training points and labels alongside each data set's testing points and labels}}{19}{figure.caption.14}\protected@file@percent }
\newlabel{fig:dataset_high}{{13}{19}{A high level overview flowchart of the process of initializing and saving the total training points and labels alongside each data set's testing points and labels}{figure.caption.14}{}}
\abx@aux@cite{0}{dollar_2009_pedestrian}
\abx@aux@segm{0}{0}{dollar_2009_pedestrian}
\abx@aux@cite{0}{dollar_2009_pedestrian}
\abx@aux@segm{0}{0}{dollar_2009_pedestrian}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{chicco_eval_2023}
\abx@aux@segm{0}{0}{chicco_eval_2023}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces A flowchart of the process of extracting the positive data samples (with some degree of random padding to avoid cropped positive bias) and the process of constructing negative samples }}{21}{figure.caption.15}\protected@file@percent }
\newlabel{fig:dataset_low}{{14}{21}{A flowchart of the process of extracting the positive data samples (with some degree of random padding to avoid cropped positive bias) and the process of constructing negative samples}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Evaluation Metrics}{21}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}The Basic Confusion Matrix Rates}{21}{subsubsection.3.3.1}\protected@file@percent }
\abx@aux@cite{0}{conf_matrix}
\abx@aux@segm{0}{0}{conf_matrix}
\abx@aux@cite{0}{conf_matrix}
\abx@aux@segm{0}{0}{conf_matrix}
\abx@aux@cite{0}{chicco_eval_2023}
\abx@aux@segm{0}{0}{chicco_eval_2023}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Positive And Negative Window Samples For Each Data Set at Each Window Size.}}{22}{table.caption.16}\protected@file@percent }
\newlabel{table:window_size_samples}{{2}{22}{Positive And Negative Window Samples For Each Data Set at Each Window Size}{table.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces An example of a confusion matrix for binary classification. Source: \blx@tocontentsinit {0}\cite {conf_matrix}}}{22}{figure.caption.17}\protected@file@percent }
\newlabel{fig:conf_matrix}{{15}{22}{An example of a confusion matrix for binary classification. Source: \cite {conf_matrix}}{figure.caption.17}{}}
\abx@aux@cite{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@segm{0}{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\abx@aux@cite{0}{cornell_log_regression_notes}
\abx@aux@segm{0}{0}{cornell_log_regression_notes}
\abx@aux@cite{0}{platt1999probabilistic}
\abx@aux@segm{0}{0}{platt1999probabilistic}
\abx@aux@cite{0}{scikit-learn_svm}
\abx@aux@segm{0}{0}{scikit-learn_svm}
\abx@aux@cite{0}{scikit-learn_svm}
\abx@aux@segm{0}{0}{scikit-learn_svm}
\abx@aux@cite{0}{martin1997det}
\abx@aux@segm{0}{0}{martin1997det}
\abx@aux@cite{0}{scikit-learn_svm}
\abx@aux@segm{0}{0}{scikit-learn_svm}
\abx@aux@cite{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@segm{0}{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@cite{0}{Maier_Hein_2024_mcc_proposal}
\abx@aux@segm{0}{0}{Maier_Hein_2024_mcc_proposal}
\abx@aux@cite{0}{Maier_Hein_2024_mcc_proposal}
\abx@aux@segm{0}{0}{Maier_Hein_2024_mcc_proposal}
\abx@aux@cite{0}{chicco_eval_2023}
\abx@aux@segm{0}{0}{chicco_eval_2023}
\abx@aux@cite{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@segm{0}{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@cite{0}{chicco_eval_2023}
\abx@aux@segm{0}{0}{chicco_eval_2023}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Confidence Threshold Curves}{23}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Matthew's Correlation Coefficient}{24}{subsubsection.3.3.3}\protected@file@percent }
\abx@aux@cite{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@segm{0}{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@cite{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@segm{0}{0}{chicco_jurman_2020_mcc_f1}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dollar_2012_pedestrian}
\abx@aux@segm{0}{0}{dollar_2012_pedestrian}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces An example of an MCC-F1 curve. Unit-normalized Matthews correlation coefficient (MCC) plotted against the F1 score (the harmonic mean between precision and recall). The random line indicates that a random classifier can achieve a unit-normalized MCC of 0.5. The point of perfect performance is (1,1), representing an ideal classifier that correctly classifies every instance. Conversely, the point of worst performance is (0,0), attained by a classifier that misclassifies all instances. The best threshold point is the location on the curve that is nearest to (1,1). 5 various threshold $\tau $ values are scattered along the curve. Source: Image by Me, generated with code in appendix \ref {appendix:mcc_f1_curves}}}{25}{figure.caption.18}\protected@file@percent }
\newlabel{fig:mcc_f1_example}{{16}{25}{An example of an MCC-F1 curve. Unit-normalized Matthews correlation coefficient (MCC) plotted against the F1 score (the harmonic mean between precision and recall). The random line indicates that a random classifier can achieve a unit-normalized MCC of 0.5. The point of perfect performance is (1,1), representing an ideal classifier that correctly classifies every instance. Conversely, the point of worst performance is (0,0), attained by a classifier that misclassifies all instances. The best threshold point is the location on the curve that is nearest to (1,1). 5 various threshold $\tau $ values are scattered along the curve. Source: Image by Me, generated with code in appendix \ref {appendix:mcc_f1_curves}}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The equation for Matthew's Correlation Coefficient. The values of MCC are bounded within the range $[-1;1]$, where 1 represents a perfect prediction, 0 represents random prediction and -1 total disagreement between prediction and observation. Refer to \blx@tocontentsinit {0}\cite {chicco_jurman_2020_mcc_f1} regarding the necessary normalization to make the MCC values bounded within $[0;1]$ so that they can be plotted against F1 scores (which themselves are bounded in $[0;1]$)}}{25}{figure.caption.19}\protected@file@percent }
\abx@aux@cite{0}{dietterich_1998_mcnemar}
\abx@aux@segm{0}{0}{dietterich_1998_mcnemar}
\abx@aux@cite{0}{raschka_2018_mcnemar}
\abx@aux@segm{0}{0}{raschka_2018_mcnemar}
\abx@aux@cite{0}{raschka_2018_mcnemar}
\abx@aux@segm{0}{0}{raschka_2018_mcnemar}
\abx@aux@cite{0}{raschka_2018_mcnemar}
\abx@aux@segm{0}{0}{raschka_2018_mcnemar}
\abx@aux@cite{0}{dietterich_1998_mcnemar}
\abx@aux@segm{0}{0}{dietterich_1998_mcnemar}
\abx@aux@cite{0}{raschka_2018_mcnemar}
\abx@aux@segm{0}{0}{raschka_2018_mcnemar}
\abx@aux@cite{0}{dietterich_1998_mcnemar}
\abx@aux@segm{0}{0}{dietterich_1998_mcnemar}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}McNemar's Test for Pairwise Classifier Comparison}{26}{subsubsection.3.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Confusion matrix layout in the context of McNemar's test. Source: \blx@tocontentsinit {0}\cite {raschka_2018_mcnemar} Code for the construction of such a matrix can be found in appendix \ref {appendix:mcnemar}}}{26}{figure.caption.20}\protected@file@percent }
\newlabel{fig:confusion_mcnemar}{{18}{26}{Confusion matrix layout in the context of McNemar's test. Source: \cite {raschka_2018_mcnemar} Code for the construction of such a matrix can be found in appendix \ref {appendix:mcnemar}}{figure.caption.20}{}}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{madk_2008_perceptual}
\abx@aux@segm{0}{0}{madk_2008_perceptual}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Model Preparation}{27}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Preprocessing: Grayscale Image Transformation}{27}{subsubsection.3.4.1}\protected@file@percent }
\newlabel{eq:colour_map}{{3.2}{27}{Preprocessing: Grayscale Image Transformation}{equation.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Computing HOG Features}{28}{subsubsection.3.4.2}\protected@file@percent }
\abx@aux@cite{0}{chang_lin_2011_libsvm}
\abx@aux@segm{0}{0}{chang_lin_2011_libsvm}
\abx@aux@cite{0}{scikit-learn_svm}
\abx@aux@segm{0}{0}{scikit-learn_svm}
\abx@aux@cite{0}{scikit-learn_svm}
\abx@aux@segm{0}{0}{scikit-learn_svm}
\abx@aux@cite{0}{uc_berkeley_sgd}
\abx@aux@segm{0}{0}{uc_berkeley_sgd}
\abx@aux@cite{0}{uc_berkeley_sgd}
\abx@aux@segm{0}{0}{uc_berkeley_sgd}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces A flowchart of the process of computing HOG features with custom block stride values}}{29}{figure.caption.21}\protected@file@percent }
\newlabel{fig:hog_flowchart}{{19}{29}{A flowchart of the process of computing HOG features with custom block stride values}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Choosing an SVM}{29}{subsubsection.3.4.3}\protected@file@percent }
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\abx@aux@cite{0}{dalal_2005_histograms}
\abx@aux@segm{0}{0}{dalal_2005_histograms}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The evaluation metrics of a LinearSVC and SGDClassifier SVM implementations, trained on the standard HOG feature parameters \blx@tocontentsinit {0}\cite {dalal_2005_histograms}: $128\times 64$ windows with $8\times 8$ pixels per cell, $2\times 2$ cells per block, $1\times 1$ block strides. Source: Image by Me, generated with code in appendix \ref {appendix:evaluate_metrics}}}{30}{table.caption.22}\protected@file@percent }
\newlabel{tab:liblinear_vs_sgd_table}{{3}{30}{The evaluation metrics of a LinearSVC and SGDClassifier SVM implementations, trained on the standard HOG feature parameters \cite {dalal_2005_histograms}: $128\times 64$ windows with $8\times 8$ pixels per cell, $2\times 2$ cells per block, $1\times 1$ block strides. Source: Image by Me, generated with code in appendix \ref {appendix:evaluate_metrics}}{table.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces An MCC-F1 curve of both LinearSVC and SGDClassifier trained on the standard HOG feature parameters \blx@tocontentsinit {0}\cite {dalal_2005_histograms}. Notice that the best performing $\tau $ value for SGDClassifier is negative, as $\tau $ identifies the distance which allows a point to be classified as a positive. This relates to Soft Constraint SVMs mentioned in section \ref {sec:soft_constraint_svm}.}}{31}{figure.caption.23}\protected@file@percent }
\newlabel{fig:liblinear_vs_sgd_curve}{{20}{31}{An MCC-F1 curve of both LinearSVC and SGDClassifier trained on the standard HOG feature parameters \cite {dalal_2005_histograms}. Notice that the best performing $\tau $ value for SGDClassifier is negative, as $\tau $ identifies the distance which allows a point to be classified as a positive. This relates to Soft Constraint SVMs mentioned in section \ref {sec:soft_constraint_svm}}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{References}{32}{figure.caption.23}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendices}{37}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Python Code Implementations}{37}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.1}Grayscale Transformation}{37}{subsubsection.A.1.1}\protected@file@percent }
\newlabel{appendix:grayscale}{{A.1.1}{37}{Grayscale Transformation}{subsubsection.A.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.2}Central Differences Derivative Mask}{37}{subsubsection.A.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.3}Holistic Derivative Mask}{38}{subsubsection.A.1.3}\protected@file@percent }
\newlabel{appendix:holistic_der_mask}{{A.1.3}{38}{Holistic Derivative Mask}{subsubsection.A.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.4}Modified HOG Computation}{38}{subsubsection.A.1.4}\protected@file@percent }
\newlabel{appendix:hog}{{A.1.4}{38}{Modified HOG Computation}{subsubsection.A.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.5}Caltech Data Set Transformation}{41}{subsubsection.A.1.5}\protected@file@percent }
\newlabel{appendix:caltech_transform}{{A.1.5}{41}{Caltech Data Set Transformation}{subsubsection.A.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.6}Retain 30th Caltech Data Set Frame}{46}{subsubsection.A.1.6}\protected@file@percent }
\newlabel{appendix:caltech_30_frame}{{A.1.6}{46}{Retain 30th Caltech Data Set Frame}{subsubsection.A.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.7}Pedestrian Data Set Construction}{46}{subsubsection.A.1.7}\protected@file@percent }
\newlabel{appendix:dataset}{{A.1.7}{46}{Pedestrian Data Set Construction}{subsubsection.A.1.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.8}Training a Soft Constraint SVM}{53}{subsubsection.A.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.9}Plotting MCC-F1 Curves}{55}{subsubsection.A.1.9}\protected@file@percent }
\newlabel{appendix:mcc_f1_curves}{{A.1.9}{55}{Plotting MCC-F1 Curves}{subsubsection.A.1.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.10}Evaluate Pedestrian Classifier}{59}{subsubsection.A.1.10}\protected@file@percent }
\newlabel{appendix:evaluate_metrics}{{A.1.10}{59}{Evaluate Pedestrian Classifier}{subsubsection.A.1.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.11}Construct McNemar's Confusion Matrix}{61}{subsubsection.A.1.11}\protected@file@percent }
\newlabel{appendix:mcnemar}{{A.1.11}{61}{Construct McNemar's Confusion Matrix}{subsubsection.A.1.11}{}}
\gdef\minted@oldcachelist{,
  default.pygstyle,
  FFE210CB075226DD19799B109A36E6A1541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  BCD49CA138781DB7E0DF1AAB74373063541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  4A15DAB82593FDCFFA4DC9F67F292D53541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  04FBFC7180B9B651C75963620BF33310541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  C72FB23A2CC59952166B7C100527246E541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  F32024ED2C8EBB520EA23B1C3B1652C2541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  2C6A5956D86FB00DD2BCD59C0A88E202541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  50EA7190618977F5FB1DEB7B38B2FC1C541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  CDEFE5D2B22D2B4A8BE06B02C1A6C135541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  2A9CD09A61F33777DB7965D9D094E59E541C68F80C6A6F06151AFD63BAE50EBC.pygtex,
  BB4DA6F394693255F2B94070E44DA1B4541C68F80C6A6F06151AFD63BAE50EBC.pygtex}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Tables of Data}{62}{subsection.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.1}INRIA Evaluation}{62}{subsubsection.A.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.2}Caltech Evaluation}{62}{subsubsection.A.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.3}PnPLO Evaluation}{62}{subsubsection.A.2.3}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{57638A246D5627567296E5163F306286}
\abx@aux@defaultrefcontext{0}{conf_matrix}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{quadratic_programming}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{madk_2008_perceptual}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{chang_lin_2011_libsvm}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{chicco_jurman_2020_mcc_f1}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{chicco_eval_2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{dalal_2005_histograms}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{scikit-learn_svm}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{dietterich_1998_mcnemar}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{dollar_2009_pedestrian}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{dollar_2012_pedestrian}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{piotrdollr_2012_crosstalk}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{everingham_2009_pascal}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{faraji_2006_ccd}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{svm_mri}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{karthika_2020_addressing}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{lowe_2004_distinctive}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Maier_Hein_2024_mcc_proposal}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{martin1997det}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{mathworks_vbbLabeler}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{what_is_ml}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ng_support}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{niebles2012edge}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{derek_2020_svm}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{platt1999probabilistic}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{raschka_2018_mcnemar}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{shidlovskiy_2020_reducing}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{slootmans_2021_european}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{inria_improved}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{uc_berkeley_sgd}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{supervised_learning}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cornell_svm}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cornell_svm_continued}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cornell_decision_trees}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cornell_perceptron}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cornell_naive_bayes}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cornell_log_regression_notes}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cornell_nn}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cornell_svm_notes}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zhou_2021_research}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zia_2015_why}{nty/global//global/global}
\gdef\svg@ink@ver@settings{{\m@ne }{inkscape}{1}}
\gdef \@abspage@last{66}
